{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jewish-healthcare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg, Robot\n",
    "from SCSCtrl import TTLServo\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "significant-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [YOLO TensorRT Engine Loader] ---\n",
    "\n",
    "class TrtYolo:\n",
    "    def __init__(self, engine_path, input_shape=(1, 3, 640, 640)):\n",
    "        self.logger = trt.Logger(trt.Logger.WARNING)\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "\n",
    "        with open(engine_path, \"rb\") as f:\n",
    "            self.engine = self.runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "        self.context = self.engine.create_execution_context()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.bindings = []\n",
    "        self.stream = cuda.Stream()\n",
    "\n",
    "        for binding in self.engine:\n",
    "            size = trt.volume(self.engine.get_binding_shape(binding))\n",
    "            dtype = trt.nptype(self.engine.get_binding_dtype(binding))\n",
    "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "\n",
    "            self.bindings.append(int(device_mem))\n",
    "            if self.engine.binding_is_input(binding):\n",
    "                self.inputs.append({\"host\": host_mem, \"device\": device_mem})\n",
    "            else:\n",
    "                self.outputs.append({\"host\": host_mem, \"device\": device_mem})\n",
    "\n",
    "    def infer(self, img):\n",
    "        np.copyto(self.inputs[0][\"host\"], img.ravel())\n",
    "\n",
    "        cuda.memcpy_htod_async(\n",
    "            self.inputs[0][\"device\"], self.inputs[0][\"host\"], self.stream\n",
    "        )\n",
    "\n",
    "        self.context.execute_async_v2(\n",
    "            bindings=self.bindings, stream_handle=self.stream.handle\n",
    "        )\n",
    "\n",
    "        for out in self.outputs:\n",
    "            cuda.memcpy_dtoh_async(out[\"host\"], out[\"device\"], self.stream)\n",
    "\n",
    "        self.stream.synchronize()\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "celtic-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [1. ëª¨ë¸ ë° ì¥ì¹˜ ì„¤ì •] ---\n",
    "# ë¼ì¸ íŠ¸ë˜í‚¹ ëª¨ë¸ ë¡œë“œ (ResNet18)\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model.load_state_dict(torch.load('best_steering_model_xy_test.pth'))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device).eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "labeled-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_trt = TrtYolo(\"best.engine\")\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secondary-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "occupied-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [2. ì‹œí€€ìŠ¤ ë° ìƒíƒœ ë³€ìˆ˜] ---\n",
    "# ì£¼í™©(orange) ë…¸ë“œëŠ” ê±´ë„ˆë›°ê³ , ì•„ë˜ ìˆœì„œëŒ€ë¡œ ê°ì§€í•©ë‹ˆë‹¤.\n",
    "color_ranges = {\n",
    "    'green':  ([40, 30, 50], [80, 255, 255]),\n",
    "    'blue':   ([95, 120, 70], [115, 255, 255]),\n",
    "    'purple': ([120, 70, 70], [155, 255, 255]),\n",
    "    'red':    ([0, 100, 100], [10, 255, 255]),\n",
    "    'yellow': ([0, 30, 140], [35, 100, 255])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reduced-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sequence = ['green', 'purple', 'blue', 'red', 'yellow']\n",
    "current_step = 0\n",
    "is_scanning = False\n",
    "observation_results = [] # ì„œë²„ ì „ì†¡ìš© ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "SERVER_URL = \"http://172.20.10.6:8888/agv/upload_observation\" # FastAPI ì£¼ì†Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bigger-source",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce111ec54ff04e3683715bd2ee1e3de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- [3. ìœ„ì ¯ ì„¤ì • (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)] ---\n",
    "camera = Camera()\n",
    "image_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parliamentary-focus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot = Robot()\n",
    "#TTLServo.servoAngleCtrl(5, 1, 1, 150) # Yì¶• 1ë„\n",
    "#TTLServo.servoAngleCtrl(1, 0, 1, 150)\n",
    "TTLServo.servoAngleCtrl(5, -50, 1, 150) # Yì¶• (ë†’ì´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complex-adolescent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afdda687f674615ad7d34bc37a1ab1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.16, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58267b0954de40fabeb8b3605a504b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.13, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ae6a4e979d4e70ab6a608827d1b60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70aab4689224913a6d7f7e1ffe2c6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.16, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.13, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "saved-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7185964bc1b347fd8df5c83a6c5649ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acb8e7e87d1424db0a0969242c49482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a05b39cfe7485a992a8f8dd1d67305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hairy-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [4. ì£¼ìš” ê¸°ëŠ¥ í•¨ìˆ˜] ---\n",
    "\n",
    "def send_to_server():\n",
    "    \"\"\"ëª¨ë“  ì •ì°° ì¢…ë£Œ í›„ ì„œë²„ì— ì¼ê´„ ì—…ë¡œë“œ\"\"\"\n",
    "    cycle_id = datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M\")\n",
    "    payload = {\n",
    "        \"cycle_id\": cycle_id,\n",
    "        \"agv_id\": \"AGV1\",\n",
    "        \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"observations\": observation_results\n",
    "    }\n",
    "    \n",
    "    # ì„œë²„ë¡œ ë³´ë‚¼ ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ë¡œì»¬ ì‚¬ì§„ ì‚¬ìš©)\n",
    "    files = []\n",
    "    for res in observation_results:\n",
    "        node = res['node']\n",
    "        filename = f\"{node}.jpg\"\n",
    "        try:\n",
    "            files.append((\"images\", (filename, open(filename, \"rb\"), \"image/jpeg\")))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {filename} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    try:\n",
    "        data = {\"payload\": json.dumps(payload)}\n",
    "        res = requests.post(SERVER_URL, data=data, files=files)\n",
    "        print(f\"ì„œë²„ ì‘ë‹µ: {res.status_code}, {res.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ì—…ë¡œë“œ ì—ëŸ¬: {e}\")\n",
    "    finally:\n",
    "        for _, f in files: f[1].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "together-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_yolo_on_local_file(node_name):\n",
    "    \"\"\"\n",
    "    TensorRT YOLO ì—”ì§„ì„ ì‚¬ìš©í•´ ë¡œì»¬ ì´ë¯¸ì§€ ì¶”ë¡ \n",
    "    - ì¶œë ¥ shape ê°€ì • âŒ\n",
    "    - reshape âŒ\n",
    "    - ì˜ˆì™¸ ë°œìƒ âŒ\n",
    "    - confidence ê°’ì€ raw outputì˜ max ê°’ìœ¼ë¡œ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "\n",
    "    img_path = f\"{node_name}.jpg\"\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"[YOLO] image not found: {img_path}\")\n",
    "        return {\"result\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "    # ---------------------------\n",
    "    # 1. Preprocess (YOLO ì…ë ¥)\n",
    "    # ---------------------------\n",
    "    img_resized = cv2.resize(img, (640, 640))\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    img_norm = img_rgb.astype(np.float32) / 255.0\n",
    "    img_chw = np.transpose(img_norm, (2, 0, 1))\n",
    "    input_tensor = np.expand_dims(img_chw, axis=0).astype(np.float32)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 2. TensorRT inference\n",
    "    # ---------------------------\n",
    "    try:\n",
    "        outputs = yolo_trt.infer(input_tensor)\n",
    "    except Exception as e:\n",
    "        print(\"[YOLO] TensorRT inference error:\", e)\n",
    "        return {\"result\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "    if not outputs or outputs[0][\"host\"] is None:\n",
    "        print(\"[YOLO] empty output\")\n",
    "        return {\"result\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3. Output ì²˜ë¦¬ (ğŸ”¥ ì ˆëŒ€ reshape ì•ˆ í•¨)\n",
    "    # ---------------------------\n",
    "    raw = outputs[0][\"host\"]\n",
    "\n",
    "    if raw.size == 0:\n",
    "        return {\"result\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "    # confidence = raw tensorì˜ ìµœëŒ€ê°’\n",
    "    conf_raw = float(np.max(raw))\n",
    "    conf = max(0.0, min(conf_raw, 1.0))\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4. ê²°ê³¼ ë§¤í•‘ (ì„ì‹œ ë¡œì§)\n",
    "    # ---------------------------\n",
    "    # thresholdëŠ” look_right_and_scan()ì—ì„œ íŒë‹¨\n",
    "    result = \"normal\" if conf > 0.5 else \"unknown\"\n",
    "\n",
    "    return {\n",
    "        \"result\": result,\n",
    "        \"confidence\": conf\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fifth-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_TIMEOUT = 5.0        # ìµœì†Œ 5ì´ˆ ë£¨í”„\n",
    "YOLO_THRESHOLD = 0.\n",
    "\n",
    "def look_right_and_scan():\n",
    "    global is_scanning, current_step\n",
    "    is_scanning = True\n",
    "    robot.stop()\n",
    "    \n",
    "    node_name = target_sequence[current_step]\n",
    "    print(f\"[SCAN] {node_name} ì‹œì‘\")\n",
    "\n",
    "    try:\n",
    "        # 1. ì¹´ë©”ë¼ ë“¤ê¸° (ì¤€ë¹„)\n",
    "        TTLServo.servoAngleCtrl(5, 1, 1, 150)\n",
    "        time.sleep(3.0)\n",
    "\n",
    "        # 2. ì˜¤ë¥¸ìª½ íšŒì „\n",
    "        TTLServo.servoAngleCtrl(1, 80, 1, 150)\n",
    "        time.sleep(3.0)\n",
    "\n",
    "        # 3. ì¹´ë©”ë¼ ë‚´ë¦¬ê¸° (ì´¬ì˜ ê°ë„)\n",
    "        TTLServo.servoAngleCtrl(5, -30, 1, 150)\n",
    "        time.sleep(3.0)\n",
    "\n",
    "        # 4. YOLO ì‹œì‘ (íƒ€ì„ì•„ì›ƒ êµ¬ê°„)\n",
    "        start_time = time.time()\n",
    "        last_result = {\"result\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "        while time.time() - start_time < YOLO_TIMEOUT:\n",
    "            try:\n",
    "                yolo_res = run_yolo_on_local_file(node_name)\n",
    "                if yolo_res is not None:\n",
    "                    last_result = yolo_res\n",
    "                    if yolo_res[\"confidence\"] >= YOLO_THRESHOLD:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] YOLO ì¶”ë¡  ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        # 5. ê²°ê³¼ ì €ì¥\n",
    "        observation_results.append({\n",
    "            \"node\": node_name,\n",
    "            \"yolo\": last_result\n",
    "        })\n",
    "\n",
    "    finally:\n",
    "        # 6~8ë²ˆ ê³¼ì •: ì–´ë–¤ ì—ëŸ¬ê°€ ë‚˜ë”ë¼ë„ 'ë°˜ë“œì‹œ' ì‹¤í–‰ë˜ì–´ì•¼ í•˜ëŠ” ë³µê·€ ë¡œì§\n",
    "        print(f\"[RECOVERY] {node_name} ë³µê·€ ì‹œí€€ìŠ¤ ì‹œì‘\")\n",
    "        \n",
    "        # 6. ì¹´ë©”ë¼ ë‹¤ì‹œ ë“¤ê¸° (ì´ë™ì„ ìœ„í•´)\n",
    "        TTLServo.servoAngleCtrl(5, 1, 1, 150)\n",
    "        time.sleep(1.2) # ì‹œê°„ì„ ì¡°ê¸ˆ ë” ë„‰ë„‰íˆ ë°°ë¶„\n",
    "\n",
    "        # 7. ì •ë©´ ë³´ê¸°\n",
    "        TTLServo.servoAngleCtrl(1, 0, 1, 150)\n",
    "        time.sleep(1.2)\n",
    "\n",
    "        # 8. ì£¼í–‰ ê°ë„ë¡œ ì„¸íŒ…\n",
    "        TTLServo.servoAngleCtrl(5, -50, 1, 150)\n",
    "        time.sleep(1.0)\n",
    "\n",
    "        is_scanning = False\n",
    "        current_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wired-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_color(image, color_name):\n",
    "    \"\"\"íŠ¹ì • ROI ë‚´ ìƒ‰ìƒ ë¹„ìœ¨ ê°ì§€\"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array(color_ranges[color_name][0])\n",
    "    upper = np.array(color_ranges[color_name][1])\n",
    "    roi = hsv[160:220, 50:170]\n",
    "    mask = cv2.inRange(roi, lower, upper)\n",
    "    mask_ratio = np.sum(mask > 0) / mask.size\n",
    "    return mask_ratio > 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "induced-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜] ---\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "frame_count = 0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, is_scanning, current_step, frame_count\n",
    "    \n",
    "    if is_scanning:\n",
    "        return\n",
    "\n",
    "    image = change['new']\n",
    "    frame_count += 1\n",
    "\n",
    "    # [A] ìƒ‰ìƒ ê°ì§€ ë¡œì§\n",
    "    if frame_count % 3 == 0:\n",
    "        target_color = target_sequence[current_step]\n",
    "        if detect_color(image, target_color):\n",
    "            if target_color == 'yellow':\n",
    "                print(\"Yellow ë…¸ë“œ(ì¢…ë£Œ) ë„ë‹¬. ì „ì†¡ ì¤‘...\")\n",
    "                robot.stop()\n",
    "                camera.unobserve(execute, names='value')\n",
    "                send_to_server()\n",
    "                return\n",
    "            \n",
    "            # ì£¼í™© ë…¸ë“œëŠ” ê°ì§€ ì‹œí€€ìŠ¤ì— ì—†ìœ¼ë¯€ë¡œ ìë™ìœ¼ë¡œ ìŠ¤í‚µë¨\n",
    "            look_right_and_scan()\n",
    "            frame_count = 0\n",
    "            return\n",
    "\n",
    "    # [B] ë¼ì¸ íŠ¸ë˜í‚¹ ì£¼í–‰ ë¡œì§\n",
    "    xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "turkish-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í–‰ ì‹œì‘\n",
    "execute({'new': camera.value})\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# camera.unobserve(execute, names='value')\n",
    "# time.sleep(0.1)\n",
    "# robot.stop()\n",
    "# camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-charm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
